---
phase: 02-explorer-agent
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/llm/foundry_client.py
  - src/vision/game_state.py
  - src/vision/prompts.py
  - src/vision/foundry_vision.py
  - src/vision/__init__.py
  - scripts/foundry_llm_smoke.py
  - scripts/vision_smoke.py
autonomous: true

must_haves:
  truths:
    - "FoundryLLMClient can make a real HTTP call when credentials are configured"
    - "A screenshot can be converted into a structured GameState object"
    - "State extraction has a strict JSON schema and robust parsing"
  artifacts:
    - path: "src/llm/foundry_client.py"
      provides: "FoundryLLMClient real HTTP implementation with mock fallback"
      contains: "class FoundryLLMClient"
    - path: "src/vision/game_state.py"
      provides: "Typed representation of game state (screen, ui hints, notes)"
      contains: "class GameState"
    - path: "src/vision/foundry_vision.py"
      provides: "LLM vision wrapper that returns GameState"
      contains: "def state_from_screenshot"
    - path: "scripts/vision_smoke.py"
      provides: "Smoke tool: load screenshot -> print state"
      contains: "--image"
  key_links:
    - from: "src/llm/foundry_client.py"
      to: "FOUNDRY_ENDPOINT"
      via: "Azure AI Foundry OpenAI-compatible REST call"
      pattern: "FOUNDRY_ENDPOINT"
    - from: "src/vision/foundry_vision.py"
      to: "src/llm/client.py"
      via: "LLMClient.vision_json"
      pattern: "vision_json"
---

<objective>
Implement the LLM-vision-to-state pipeline: take a screenshot and produce a stable, structured `GameState` that agents can reason over.

Purpose: Exploration needs a feedback signal; screenshots alone are not actionable.
Output: `src/vision/*` plus a smoke tool.
</objective>

<execution_context>
@/home/ubuntu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@../../plans/stream-qa-swarm.md

# Prior phase artifacts this phase assumes exist
@infra/foundry_config.json
@src/llm/client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement FoundryLLMClient real HTTP calls (text + vision_json) with mock fallback</name>
  <files>
src/llm/foundry_client.py
scripts/foundry_llm_smoke.py
  </files>
  <action>
Implement a working `FoundryLLMClient` that can talk to Azure AI Foundry / Azure OpenAI-compatible REST endpoints.

- Implement `text(prompt) -> str` and `vision_json(prompt, image_bytes, schema) -> dict` using a real `POST /openai/deployments/{deployment}/chat/completions?api-version=...` call.
- Read configuration from env vars:
  - `FOUNDRY_ENDPOINT`, `FOUNDRY_DEPLOYMENT`, `FOUNDRY_API_VERSION`, `FOUNDRY_API_KEY`
- For `vision_json`:
  - send an `image_url` message part using `data:image/png;base64,...` (base64 from `image_bytes`)
  - instruct the model to respond with JSON only; validate/parse to `dict`
  - use the provided `schema` for validation after parsing (do not rely on the model perfectly following it).
- Mock fallback:
  - if `FOUNDRY_MOCK=1` (or `--mock-response` in the smoke script), return a deterministic fixture response and skip network.
- Add `scripts/foundry_llm_smoke.py`:
  - default to mock mode and prints a sample `text()` and `vision_json()` output
  - `--live` runs the real HTTP call (fails fast with clear error if env vars are missing).
  </action>
  <verify>
python3 -m compileall src
python3 scripts/foundry_llm_smoke.py --help
python3 scripts/foundry_llm_smoke.py
  </verify>
  <done>
With `FOUNDRY_MOCK=1`, the smoke script runs offline; with env vars set, it performs a real HTTP call.
  </done>
</task>

<task type="auto">
  <name>Task 2: Define GameState model + vision JSON schema contract</name>
  <files>
 src/vision/__init__.py
 src/vision/game_state.py
 src/vision/prompts.py
  </files>
  <action>
Create a strict, minimal state model that is stable across games.

- Define `GameState` with fields that are directly useful to automation:
  - `screen_id` (string, coarse-grained)
  - `summary` (string)
  - `action_hints` (list of strings)
  - `ui_elements` (list of {label, type, location?} or keep as strings if simpler)
  - `is_loading` (bool)
  - `warnings` (list of strings)
- In `src/vision/prompts.py`, define a single prompt template and a JSON schema dict that constrains the model output.
- Keep the model + schema intentionally conservative so parsing is reliable.
  </action>
  <verify>
python3 -m compileall src
python3 -c "from src.vision.game_state import GameState; print(GameState.__name__)"
  </verify>
  <done>
`GameState` is importable and the prompt/schema live in one predictable place.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement FoundryVision wrapper + smoke script</name>
  <files>
 src/vision/foundry_vision.py
 scripts/vision_smoke.py
  </files>
  <action>
Wire `LLMClient` to return `GameState` from a screenshot.

- Implement `state_from_screenshot(llm: LLMClient, image_path: str) -> GameState`.
- Make parsing defensive:
  - validate JSON matches required keys
  - coerce types where safe
  - add parse errors to `warnings` rather than crashing.
- Add `scripts/vision_smoke.py`:
  - accepts `--image path/to.png`
  - loads image bytes
  - calls `state_from_screenshot`
  - prints the state as JSON for debugging.
- If Foundry credentials are not configured, allow a `--mock-response path.json` mode for development.
   - In `--mock-response` mode, do not require an image or live Foundry credentials; still validate/print a `GameState`.
  </action>
  <verify>
  python3 -m compileall src
  python3 scripts/vision_smoke.py --help
  python3 -c "import json, pathlib; p=pathlib.Path('artifacts/mock_vision_response.json'); p.parent.mkdir(parents=True, exist_ok=True); json.dump({'screen_id':'mock','summary':'mock state','action_hints':['click START'],'ui_elements':[],'is_loading':False,'warnings':[]}, p.open('w')); print(p)"
  python3 scripts/vision_smoke.py --mock-response artifacts/mock_vision_response.json
  </verify>
  <done>
Given an image (or mock response), the script prints a structured state JSON.
  </done>
</task>

</tasks>

<verification>
- Running `scripts/vision_smoke.py --mock-response ...` works without external creds.
- Running `scripts/foundry_llm_smoke.py` in mock mode works without external creds.
</verification>

<success_criteria>
- EXPL-02 unblocked: vision produces a stable, typed `GameState` from screenshots.
</success_criteria>

<output>
After completion, create `.planning/phases/02-explorer-agent/02-01-SUMMARY.md`
</output>
